# Webscrapping
El webscrapping o raspado, es una t茅cnica que sirve para extraer informaci贸n de un sitio web, en este proyecto se utiliz贸 la librer铆a Twint para extraer tweets de la plataforma Twitter. Se hace filtros por idioma, fechas, cantidad de tweets, etc. Podemos ver un ejemplo en el archivo [ejemplo.py]([Preprocesamiento/ejemplo.py at master 路 Jesusdrp09/Preprocesamiento 路 GitHub](https://github.com/Jesusdrp09/Preprocesamiento/blob/master/ejemplo.py))
# Preprocesamiento
En este proyecto se aplican 9 t茅cnicas de preprocesamiento: 
- Reemplazo de contracciones: desde el archivo contracciones.csv se extraen las contracciones m谩s comunes usadas en el diario vivir de los colombianos y se reemplazan por la palabra o frase estandarizada.
- Reemplazo de abreviaciones: desde el archivo abreviaciones.csv se extraen las abreviaciones m谩s comunes usadas en el diario vivir de los colombianos y se reemplazan por la palabra o frase estandarizada.
- Reemplazo de nombres de usuario: los tweets algunas veces contienen nombres de usuarios como @juanPerea000, como estos nombres de usuarios no le aportan informaci贸n a los modelos de inteligencia artificial, podemos reemplazar todos la palabra "USERNAME".
- Reemplazo de URLs: las URLs no le aportan informaci贸n a los modelos de inteligencia artificial, es por ello que se reemplazan las URL por la palabra "URL"
- Eliminaci贸n de n煤meros: los n煤meros suelen aportar informaci贸n m铆nima al modelo, es por ello que algunos casos se pueden omitir, en el proyecto actual simplemente se eliminan todos los n煤meros. 
- A帽adir etiquetas: algunas veces para expresarnos utilizamos emojis como: , estos emojis pueden ser reemplazados por las emociones que representan como "felicidad", "alegr铆a", "enojo" o "tristeza", esto con el fin de estandarizar las palabras que recibe el modelo y as铆 otorgarle m谩s informaci贸n.
- Eliminaci贸n de stopwords: los "stopwords" son palabras de un idioma que solas carecen de sentido como: el, en, un, entre otros. Est谩s palabras se pueden eliminar en modelos de Machine Learning, ya que su aporte es muy poco o nulo al an谩lisis de sentimiento. 
- Lowercasing: Hola, hola, HOLa y HOla quieren decir lo mismo, es por ello que se aplica la t茅cnica de lowercasing, la cual ayuda a colocar todas las letras en min煤scula. 
- Eliminar signos de puntuaci贸n: los signos de puntuaci贸n no aportan mucha informaci贸n al modelo, adem谩s, aparecen no importando si el sentimiento que se expresa en el tweet es positivo, negativo o neutro. Es por ello que se eliminan todos los signos de puntuaci贸n. 


Podemos ver esta informaci贸n en el archivo [prepro.py]([Preprocesamiento/prepro.py at master 路 Jesusdrp09/Preprocesamiento 路 GitHub](https://github.com/Jesusdrp09/Preprocesamiento/blob/master/prepro.py))
